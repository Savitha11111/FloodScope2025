"""Preprocessing for the FloodNet aerial imagery dataset."""
from __future__ import annotations

import argparse
import csv
import json
import pathlib
from typing import Iterable

import numpy as np
import rasterio
from rasterio.enums import Resampling
from rasterio.warp import calculate_default_transform, reproject

from datasets.download_utils import record_license
from llm.cloud_coverage import calculate_cloud_coverage

LICENSE_TEXT = "FloodNet derived products generated by FloodScope2025."


def _ensure_dirs(root: pathlib.Path) -> tuple[pathlib.Path, pathlib.Path]:
    processed = root / "processed"
    metadata_dir = root / "metadata"
    processed.mkdir(parents=True, exist_ok=True)
    metadata_dir.mkdir(parents=True, exist_ok=True)
    return processed, metadata_dir


def _harmonise_raster(src_path: pathlib.Path, dst_path: pathlib.Path, dst_crs: str = "EPSG:4326") -> None:
    with rasterio.open(src_path) as src:
        transform, width, height = calculate_default_transform(src.crs, dst_crs, src.width, src.height, *src.bounds)
        kwargs = src.meta.copy()
        kwargs.update({"crs": dst_crs, "transform": transform, "width": width, "height": height})
        with rasterio.open(dst_path, "w", **kwargs) as dst:
            for band_index in range(1, src.count + 1):
                reproject(
                    source=rasterio.band(src, band_index),
                    destination=rasterio.band(dst, band_index),
                    src_transform=src.transform,
                    src_crs=src.crs,
                    dst_transform=transform,
                    dst_crs=dst_crs,
                    resampling=Resampling.bilinear,
                )


def _discover_tiles(interim_root: pathlib.Path) -> Iterable[pathlib.Path]:
    image_files = sorted(interim_root.rglob("*_img.tif"))
    if not image_files:
        image_files = sorted(interim_root.rglob("*.tif"))
    if not image_files:
        raise FileNotFoundError("No FloodNet GeoTIFFs found. Ensure the archive was extracted using download_floodnet.py.")
    return image_files


def _write_metadata(metadata_dir: pathlib.Path, records: Iterable[dict]) -> None:
    metadata_path = metadata_dir / "floodnet_tiles.csv"
    fieldnames = ["tile_id", "image_path", "mask_path", "cloud_fraction"]
    with metadata_path.open("w", newline="", encoding="utf-8") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        for record in records:
            writer.writerow(record)


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Preprocess FloodNet imagery into harmonised GeoTIFFs")
    parser.add_argument("--output-root", type=pathlib.Path, required=True)
    parser.add_argument("--interim-root", type=pathlib.Path, default=None)
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    interim_root = args.interim_root or args.output_root / "interim"
    processed_root, metadata_dir = _ensure_dirs(args.output_root)

    records = []
    for image_path in _discover_tiles(interim_root):
        tile_id = image_path.stem.replace("_img", "")
        mask_candidates = list(image_path.parent.glob(f"{tile_id}*_msk.tif"))
        mask_path = mask_candidates[0] if mask_candidates else None

        tile_dir = processed_root / tile_id
        tile_dir.mkdir(parents=True, exist_ok=True)

        harmonised_image = tile_dir / "image.tif"
        _harmonise_raster(image_path, harmonised_image)

        harmonised_mask = None
        if mask_path:
            harmonised_mask = tile_dir / "mask.tif"
            _harmonise_raster(mask_path, harmonised_mask, dst_crs="EPSG:4326")

        cloud_fraction = calculate_cloud_coverage(str(harmonised_image))
        records.append({
            "tile_id": tile_id,
            "image_path": str(harmonised_image),
            "mask_path": str(harmonised_mask) if harmonised_mask else "",
            "cloud_fraction": f"{cloud_fraction:.4f}",
        })

    _write_metadata(metadata_dir, records)
    coverage_report = {
        "num_tiles": len(records),
        "cloud_fraction_mean": float(np.mean([float(r["cloud_fraction"]) for r in records])) if records else 0.0,
        "cloud_fraction_std": float(np.std([float(r["cloud_fraction"]) for r in records])) if records else 0.0,
    }
    with (metadata_dir / "floodnet_coverage.json").open("w", encoding="utf-8") as fh:
        json.dump(coverage_report, fh, indent=2)

    record_license(args.output_root, LICENSE_TEXT)
    print(f"Processed {len(records)} FloodNet tiles into {processed_root}.")


if __name__ == "__main__":
    main()
